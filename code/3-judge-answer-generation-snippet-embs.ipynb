{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6a9382-1d0f-442b-b8c1-dff14d593012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.57.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.11/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.11/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.11/site-packages (4.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.57.0)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.11/site-packages (1.10.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.11/site-packages (0.48.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (68.2.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.11/site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install datasets\n",
    "!pip install transformers accelerate bitsandbytes\n",
    "!pip install nltk\n",
    "!pip install tqdm\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import re\n",
    "import seaborn as sns\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e81ee-d229-47d7-bdcd-cc2bfbeeef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365f0bd6d26c4ebd8078c8c74b854246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HF_L = \"xxx\"\n",
    "login(token=HF_L)\n",
    "model = 'mistral'\n",
    "\n",
    "if model == 'llama':\n",
    "    llama_model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    llama_tokenizer = AutoTokenizer.from_pretrained(llama_model_name, use_auth_token=HF_L)\n",
    "    llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "        llama_model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        use_auth_token=HF_L\n",
    "    )\n",
    "if model == 'falcon':\n",
    "    falcon_model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "    falcon_tokenizer = AutoTokenizer.from_pretrained(falcon_model_name)\n",
    "    falcon_model = AutoModelForCausalLM.from_pretrained(\n",
    "        falcon_model_name,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "if model == 'gemma':\n",
    "    gemma_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-7b-it\")\n",
    "    gemma_model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"google/gemma-7b-it\", \n",
    "        device_map=\"auto\", \n",
    "        revision=\"float16\")\n",
    "if model == 'mistral':\n",
    "    device = \"cuda\"\n",
    "    mistral_model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "    mistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acac042a-57a9-4ca3-a515-7523d4b34ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_embeddings(prompt, seed=42):\n",
    "    inputs = llama_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    torch.manual_seed(seed)    \n",
    "    llama_model.config.output_hidden_states = True    \n",
    "    with torch.no_grad():\n",
    "        outputs = llama_model(**inputs)    \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_falcon_embeddings(prompt, seed=42):\n",
    "    if not hasattr(falcon_model, \"config\"):\n",
    "        raise ValueError(\"falcon_model is not properly initialized. Please load the model correctly.\")\n",
    "    inputs = falcon_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    torch.manual_seed(seed)\n",
    "    falcon_model.config.output_hidden_states = True\n",
    "    with torch.no_grad():\n",
    "        outputs = falcon_model(**inputs)\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_gemma_embeddings(prompt, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"    \n",
    "    gemma_model.to(device)    \n",
    "    inputs = gemma_tokenizer(prompt, return_tensors=\"pt\")  \n",
    "    input_ids = inputs[\"input_ids\"].to(device)    \n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "    gemma_model.config.output_hidden_states = True\n",
    "    with torch.no_grad():\n",
    "        outputs = gemma_model(input_ids=input_ids) \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = attention_mask.unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask    \n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)    \n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()    \n",
    "    return mean_pooled[0]\n",
    "    \n",
    "def get_mistral_embeddings(prompt, seed=42):\n",
    "    global mistral_model\n",
    "    mistral_model = mistral_model.to(\"cuda\")    \n",
    "    inputs = mistral_tokenizer(prompt, return_tensors=\"pt\")\n",
    "    inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}    \n",
    "    torch.manual_seed(seed)\n",
    "    mistral_model.config.output_hidden_states = True    \n",
    "    with torch.no_grad():\n",
    "        outputs = mistral_model(**inputs)    \n",
    "    embeddings = outputs.hidden_states[-1]\n",
    "    attention_mask = inputs[\"attention_mask\"].unsqueeze(-1)\n",
    "    embeddings = embeddings * attention_mask\n",
    "    sum_embeddings = embeddings.sum(dim=1)\n",
    "    mask_sum = attention_mask.sum(dim=1)\n",
    "    mean_pooled = sum_embeddings / mask_sum\n",
    "    mean_pooled = mean_pooled.float().detach().cpu().numpy()\n",
    "    return mean_pooled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f14cc01-6013-45d4-9c3c-70fef994a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANSWER_GENERATION_PROMPT = '''Generate an answer to the below question based on the provided snippet.\n",
    "\n",
    "question: \"{0}\"\n",
    "snippet: \"{1}\"\n",
    "'''\n",
    "\n",
    "QUESTION_GENERATION_PROMPT = '''Your task is to generate a clear and concise question based on the provided snippet and answer. Ensure that the generated question directly corresponds to the snippet's content and leads to the given answer.\n",
    "\n",
    "Here is the input:\n",
    "Snippet: \"{0}\"\n",
    "Answer: \"{1}\"\n",
    "\n",
    "Generate the most appropriate question:'''\n",
    "\n",
    "QUESTION_GENERATION_PROMPT_GEMMA = '''Generate the question which was asked regarding the below snippet and provided answer. Ensure that the generated question directly corresponds to the snippet's content and leads to the given answer.\n",
    "\n",
    "snippet: \"{0}\"\n",
    "answer: \"{1}\"\n",
    "\n",
    "The output should contain only the question (don't output the answer to the question).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee72ccc-c8f1-4749-98f4-f561f80b2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_alignment(case_embs, case_base):\n",
    "    emb1, emb2 = case_embs\n",
    "    emb1 = emb1.reshape(1, -1) if emb1.ndim == 1 else emb1\n",
    "    emb2 = emb2.reshape(1, -1) if emb2.ndim == 1 else emb2\n",
    "    alignment_scores = []\n",
    "    for past_case in case_base:\n",
    "        past_prob_emb, past_solution_emb = past_case\n",
    "        past_prob_emb = past_prob_emb.reshape(1, -1) if past_prob_emb.ndim == 1 else past_prob_emb\n",
    "        past_solution_emb = past_solution_emb.reshape(1, -1) if past_solution_emb.ndim == 1 else past_solution_emb\n",
    "        prob_similarity = cosine_similarity(emb1, past_prob_emb)\n",
    "        solution_similarity = cosine_similarity(emb2, past_solution_emb)\n",
    "        alignment_score = (prob_similarity + solution_similarity) / 2.0\n",
    "        alignment_scores.append(alignment_score)\n",
    "    return (sum(alignment_scores) / len(alignment_scores))[0][0]\n",
    "\n",
    "\n",
    "def get_embeddings(model, text):\n",
    "    if model == \"llama\":\n",
    "        return get_llama_embeddings(text)\n",
    "    elif model == \"falcon\":\n",
    "        return get_falcon_embeddings(text)\n",
    "    elif model == \"gemma\":\n",
    "        return get_gemma_embeddings(text)\n",
    "    elif model == \"mistral\":\n",
    "        return get_mistral_embeddings(text)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15de85fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Ramitha/unique-records-snippet-combination\")\n",
    "df = pd.DataFrame(dataset['rawcases'])\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    if model not in [\"llama\", \"falcon\", \"gemma\", \"mistral\"]:\n",
    "        continue\n",
    "    if (row['model'] != model):\n",
    "        continue\n",
    "    q_emb_without_context = np.array(get_embeddings(model, row[\"question\"]))\n",
    "    a_emb_without_context = np.array(get_embeddings(model, row[\"answerGenerated\"]))\n",
    "    q_emb_with_context = np.array(get_embeddings(model, row[\"question\"]  + \" \" + row[\"snippet\"]))\n",
    "    case_without_context = [q_emb_without_context, a_emb_without_context]    \n",
    "    case_with_problem_context = [q_emb_with_context, a_emb_without_context]\n",
    "    \n",
    "    case_base_without_context, case_base_with_context, case_base_with_problem_context, case_base_with_answer_context = [], [], [], []\n",
    "    for other_model in [\"llama\", \"falcon\", \"gemma\", \"mistral\"]:\n",
    "        if other_model == model:\n",
    "            continue\n",
    "        q_wo = np.array(get_embeddings(model, row[f\"question_answerGenerated_{other_model}\"]))\n",
    "        q_wc = np.array(get_embeddings(model, row[f\"question_answerGenerated_{other_model}\"] + \" \" + row[\"snippet\"]))\n",
    "        a_wo = np.array(get_embeddings(model, row[f\"reverse_answer_answerGenerated_{other_model}\"]))\n",
    "        case_base_without_context.append([q_wo, a_wo])\n",
    "        case_base_with_problem_context.append([q_wc, a_wo])\n",
    "    df.at[index, f\"ILRAlign_without_context_{model}\"] = get_case_alignment(case_without_context, case_base_without_context)\n",
    "    df.at[index, f\"ILRAlign_with_problem_context_only_{model}\"] = get_case_alignment(case_with_problem_context, case_base_with_problem_context)\n",
    "\n",
    "hf_dataset = DatasetDict({\n",
    "    'rawcases': Dataset.from_pandas(df)\n",
    "})\n",
    "hf_dataset.push_to_hub(\"Ramitha/unique-records-snippet-combination\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
